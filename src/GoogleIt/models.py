"""
This module provides wrapper classes for interacting with Google's language models, including Palm 2 and Gemini.

Palm2Model Class:
-----------------
This class serves as a wrapper for the Google Palm 2 language model.

Attributes:
- model: The initialized Palm 2 language model.

Methods:
- __init__(self) -> None:
    Initializes the Palm2Model instance.

- init(self, api_key: str) -> None:
    Initializes the Palm 2 language model using the provided API key.

    Parameters:
    - api_key (str): The API key for authentication.

- make_prompt(self, query: str, relevant_passage: str) -> str:
    Generates a prompt for the Palm 2 language model.

    Parameters:
    - query (str): The user's question.
    - relevant_passage (str): The relevant passage for context.

    Returns:
    str: The formatted prompt for the language model.

- redraft_response(self, query: str, response: str) -> str:
    Redrafts the response generated by the Palm 2 language model.

    Parameters:
    - query (str): The user's question.
    - response (str): The generated response.

    Returns:
    str: The redrafted response.

- query(self, document: str, question: str) -> str:
    Queries the Palm 2 language model for an answer.

    Parameters:
    - document (str): The reference document for context.
    - question (str): The user's question.

    Returns:
    str: The generated answer from the language model.


GeminiModel Class:
-------------------
This class serves as a wrapper for the Google Gemini language model.

Attributes:
- model: The initialized Gemini language model.

Methods:
- __init__(self) -> None:
    Initializes the GeminiModel instance.

- init(self, api_key: str) -> None:
    Initializes the Gemini language model using the provided API key.

    Parameters:
    - api_key (str): The API key for authentication.

- make_prompt(self, query: str, relevant_passage: str) -> str:
    Generates a prompt for the Gemini language model.

    Parameters:
    - query (str): The user's question.
    - relevant_passage (str): The relevant passage for context.

    Returns:
    str: The formatted prompt for the language model.

- redraft_response(self, query: str, response: str) -> str:
    Redrafts the response generated by the Gemini language model.

    Parameters:
    - query (str): The user's question.
    - response (str): The generated response.

    Returns:
    str: The redrafted response.

- query(self, document: str, question: str) -> str:
    Queries the Gemini language model for an answer.

    Parameters:
    - document (str): The reference document for context.
    - question (str): The user's question.

    Returns:
    str: The generated answer from the language model.
"""

import google.generativeai as genai
import textwrap


class Palm2Model:
    """
    Wrapper class for interacting with the Google Palm 2 language model.

    Attributes:
    - model: The initialized Palm 2 language model.
    """

    def __init__(self) -> None:
        """Initialize the Palm2Model instance."""
        self.model = None

    def init(self, api_key: str) -> None:
        """
        Initialize the Palm 2 language model using the provided API key.

        Parameters:
        - api_key (str): The API key for authentication.
        """
        genai.configure(api_key=api_key)
        models = [m for m in genai.list_models() if 'generateText' in m.supported_generation_methods]

        if not models:
            raise ValueError("No models with text generation support found.")

        self.model = models[0]

    def make_prompt(self, query: str, relevant_passage: str) -> str:
        """
        Generate a prompt for the Palm 2 language model.

        Parameters:
        - query (str): The user's question.
        - relevant_passage (str): The relevant passage for context.

        Returns:
        str: The formatted prompt for the language model.
        """
        escaped = relevant_passage.replace("'", "").replace('"', "").replace("\n", " ")
        prompt = textwrap.dedent(f"""You are a helpful and informative bot that answers questions using text from the reference passage included below. \
            Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \
            However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \
            strike a friendly and conversational tone. \
            The length of the response should be relevant to the prompt. Provide longer responses only if asked
            If the passage is irrelevant to the answer, you may ignore it.
            Redraft the response properly with proper sentence formation. Make sure the response length is reasonable and readable
            QUESTION: '{query}'
            PASSAGE: '{escaped}'

            ANSWER:
            """)

        return prompt

    def redraft_response(self, query: str, response: str) -> str:
        """
        Redraft the response generated by the Palm 2 language model.

        Parameters:
        - query (str): The user's question.
        - response (str): The generated response.

        Returns:
        str: The redrafted response.
        """
        prompt = textwrap.dedent(f"""The following passage is the Response generated to answer the question provided below \
                                 Redraft the passage if it is not readable. If it is already readable provide me the same passage as a response \
                                 Don't provide extra background informations
            QUESTION: '{query}'
            PASSAGE: '{response}'

            ANSWER:
            """)

        temperature = 0.2
        answer = genai.generate_text(prompt=prompt,
                                      model=self.model,
                                      candidate_count=3,
                                      temperature=temperature,
                                      max_output_tokens=1500)
        return answer.candidates[0]['output']

    def query(self, document: str, question: str) -> str:
        """
        Query the Palm 2 language model for an answer.

        Parameters:
        - document (str): The reference document for context.
        - question (str): The user's question.

        Returns:
        str: The generated answer from the language model.
        """
        if self.model is None:
            raise ValueError("The language model is not initialized. Call init() with the API key first.")

        prompt = self.make_prompt(question, document)

        temperature = 0.2
        answer = genai.generate_text(prompt=prompt,
                                      model=self.model,
                                      candidate_count=3,
                                      temperature=temperature,
                                      max_output_tokens=1500)

        return self.redraft_response(question, answer.candidates[0]['output'])


class GeminiModel:
    """
    Wrapper class for interacting with the Google Gemini language model.

    Attributes:
    - model: The initialized Gemini language model.
    """

    def __init__(self) -> None:
        """Initialize the GeminiModel instance."""
        self.model = None

    def init(self, api_key: str) -> None:
        """
        Initialize the Gemini language model using the provided API key.

        Parameters:
        - api_key (str): The API key for authentication.
        """
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-pro')

    def make_prompt(self, query: str, relevant_passage: str) -> str:
        """
        Generate a prompt for the Gemini language model.

        Parameters:
        - query (str): The user's question.
        - relevant_passage (str): The relevant passage for context.

        Returns:
        str: The formatted prompt for the language model.
        """
        escaped = relevant_passage.replace("'", "").replace('"', "").replace("\n", " ")
        prompt = textwrap.dedent(f"""You are a helpful and informative bot that answers questions using text from the reference passage included below. \
            Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \
            However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \
            strike a friendly and conversational tone. \
            The length of the response should be relevant to the prompt. Provide longer responses only if asked
            If the passage is irrelevant to the answer, you may ignore it.
            Redraft the response properly with proper sentence formation. Make sure the response length is reasonable and readable
            QUESTION: '{query}'
            PASSAGE: '{escaped}'

            ANSWER:
            """)

        return prompt

    def redraft_response(self, query: str, response: str) -> str:
        """
        Redraft the response generated by the Gemini language model.

        Parameters:
        - query (str): The user's question.
        - response (str): The generated response.

        Returns:
        str: The redrafted response.
        """
        prompt = textwrap.dedent(f"""The following passage is the Response generated to answer the question provided below \
                                 Redraft the passage if it is not readable. If it is already readable provide me the same passage as a response \
                                 Don't provide extra background informations

            QUESTION: '{query}'
            PASSAGE: '{response}'

            ANSWER:
            """)

        temperature = 0.2
        answer = self.model.generate_content(prompt,
                                             generation_config=genai.types.GenerationConfig(
                                                 candidate_count=1,
                                                 max_output_tokens=1500,
                                                 temperature=temperature
                                             )
                                             )

        return answer.text

    def query(self, document: str, question: str) -> str:
        """
        Query the Gemini language model for an answer.

        Parameters:
        - document (str): The reference document for context.
        - question (str): The user's question.

        Returns:
        str: The generated answer from the language model.
        """
        if self.model is None:
            raise ValueError("The language model is not initialized. Call init() with the API key first.")

        prompt = self.make_prompt(question, document)

        temperature = 0.2
        answer = self.model.generate_content(prompt,
                                             generation_config=genai.types.GenerationConfig(
                                                 candidate_count=1,
                                                 max_output_tokens=1500,
                                                 temperature=temperature
                                             )
                                             )

        return self.redraft_response(question, answer.text)